{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgmrTcsxYjgG"
   },
   "source": [
    "# 기계학습과 인공신경망 10장: RNN(LSTM) 실습\n",
    "\n",
    "RNN(LSTM)을 이용하여 Text 데이터를 예측하는 예제.\n",
    "\n",
    "인터넷에서 hihello 의 예측에 대한 많은 유사한 예제들이 있으나 본 내용은 아래 참고 링크 1에서 가져온 것이며 참고링크 2에 추가적인 설명이 있음.\n",
    "\n",
    "참고 링크:  \n",
    "1.   https://github.com/hunkim/DeepLearningZeroToAll/blob/master/keras/klab-12-1-rnn_hello_char.py\n",
    "2.   https://docs.google.com/presentation/d/1UpZVnOvouIbXd0MAFBltSra5rRpsiJ-UyBUKGCrfYoo/edit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNClRCYYqaMy"
   },
   "source": [
    "(1) 사용할 패키지들 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2109,
     "status": "ok",
     "timestamp": 1566256603755,
     "user": {
      "displayName": "Seokhyun Yoon",
      "photoUrl": "https://lh5.googleusercontent.com/-JfY5LFELdd4/AAAAAAAAAAI/AAAAAAAAAd4/N4htyki5fQQ/s64/photo.jpg",
      "userId": "14399968853404009011"
     },
     "user_tz": -540
    },
    "id": "PbO3MXrjOWB0",
    "outputId": "d3b454a6-4d71-45a9-b561-715178fa4cc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Activation, LSTM\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZL490Vd50C3e"
   },
   "source": [
    "(2) 사용할 데이터 생성 및 입출력 포맷 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpeUVaQDcQuE"
   },
   "outputs": [],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "           \"collect wood and don't assign them tasks and work, but rather \"\n",
    "           \"teach them to long for the endless immensity of the sea.\")\n",
    "\n",
    "sentence = (\"hi hello\")\n",
    "\n",
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}\n",
    "\n",
    "input_dim = len(char_set)\n",
    "hidden_size = 7 #len(char_set)  # output dimension of RNN(LSTM) cell, can be any arbitrary integer\n",
    "num_classes = len(char_set)  # output dimension of the model\n",
    "seq_length = 5  # Number of time steps, Any arbitrary integer\n",
    "sample_size = len(sentence) - seq_length\n",
    "\n",
    "print(char_set)\n",
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Ttv9Z041NXL"
   },
   "source": [
    "(3) RNN(LSTM)을 위한 데이터 전처리\n",
    "\n",
    "1. 문자열을 Toeplitz 행렬 형태로바꾸어  입력데이터 준비\n",
    "2. 이 때 char_dic를 이용하여 문자를 숫자로 바꾸고\n",
    "3. 최종적으로 숫자를  2진 벡터로 바꿈 (one hot encoding)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5soBVOgcoARJ"
   },
   "outputs": [],
   "source": [
    "X_seqs = np.zeros([sample_size,seq_length])\n",
    "Y_seqs = np.zeros([sample_size,seq_length])\n",
    "for i in range(0, sample_size):\n",
    "   x_str = sentence[i:i + seq_length]\n",
    "   y_str = sentence[i + 1: i + seq_length + 1]\n",
    "   print(i, 'th sample: Input -> Target : ', x_str, '->', y_str)\n",
    "\n",
    "   x = [char_dic[c] for c in x_str]  # x str to index\n",
    "   y = [char_dic[c] for c in y_str]  # y str to index\n",
    "\n",
    "   X_seqs[i,] = x\n",
    "   Y_seqs[i,] = y\n",
    "    \n",
    "print('(sample_size, seq_length) = ', X_seqs.shape)\n",
    "print('숫자로 변환된 입력 데이터:')\n",
    "print(X_seqs)\n",
    "print(Y_seqs)\n",
    "\n",
    "# One-hot encoding\n",
    "x_onehot = to_categorical(X_seqs, num_classes=num_classes)\n",
    "y_onehot = to_categorical(Y_seqs, num_classes=num_classes)\n",
    "\n",
    "print('(sample_size, seq_length, input_dim) = ', x_onehot.shape)\n",
    "print(x_onehot)\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-R8wvdAl4hod"
   },
   "source": [
    "(4) 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8Zp77HrrGO6"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(hidden_size, input_shape=(seq_length, input_dim), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model.summary()\n",
    "# Store model graph in png\n",
    "# (Error occurs on in python interactive shell)\n",
    "# plot_model(model, to_file=os.path.basename(__file__) + '.png', show_shapes=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvlIGxwQtOY-"
   },
   "source": [
    "(5) 학습 (Model fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwIjOtz0xxvK"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_onehot, y_onehot, epochs=5, steps_per_epoch = 100)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sjTZcKUtZ47"
   },
   "source": [
    "(6) 학습이 잘 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGSklzXEPIiK"
   },
   "outputs": [],
   "source": [
    "def get_idx_n_str( onehot ):\n",
    "  index = np.argmax(onehot, axis=0)\n",
    "  if( np.isscalar(index) ): \n",
    "    str = char_set[index]\n",
    "  else: \n",
    "    index = np.argmax(onehot, axis=1)\n",
    "    str = [char_set[j] for j in index]\n",
    "  return index, str\n",
    "  \n",
    "\n",
    "predictions = model.predict(x_onehot, verbose=0)\n",
    "for i, prediction in enumerate(predictions):\n",
    "    # print(prediction)\n",
    "    index, str = get_idx_n_str(x_onehot[i])\n",
    "    print(i,'th Input:     ', index, ' -> ', ''.join(str))\n",
    "\n",
    "    index, str = get_idx_n_str(y_onehot[i])\n",
    "    print(i,'th Target:    ', index, ' -> ', ''.join(str))\n",
    "\n",
    "    index, str = get_idx_n_str(prediction)\n",
    "    print(i,'th Predicted: ', index, ' -> ', ''.join(str))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_practice5_RNN_hihello_190820.ipynb",
   "provenance": [
    {
     "file_id": "1V9e0sXzv3Rvwn_cklS-8UCfH0hT_BaUX",
     "timestamp": 1566199940324
    },
    {
     "file_id": "1x72-LyrS2tZXdDfg4FMASk4N2jzEnp8d",
     "timestamp": 1566198047302
    },
    {
     "file_id": "1QTaFJhMOjxFlZav1xSiaual6tY2Hsza_",
     "timestamp": 1566193166385
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
